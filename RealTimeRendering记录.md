## 第二章：图形渲染管线

### 2.1 整体架构

1. 图形渲染管线和普通流水线一样，都是一个部分流水线主要处理一部分的内容，并且可以并行计算

2. 图形渲染可以说大体分为四个阶段：

   1. 应用阶段（application stage），这个阶段主要做的工作就是包括了真正使用的软件部分，它能够计算各种我们渲染时需要的数据，有一些物理相关的计算，如碰撞检测，全局加速算法那，动画，物理模拟等等都可以在应用阶段进行计算。
   2. 几何处理阶段（Geometry processing），这个阶段主要处理变换，投影，等等各种图形处理，这个阶段要决定什么需要渲染（比如说裁剪），在哪里渲染，要怎么渲染，该阶段开始就是在GPU中计算的了
   3. 光栅化阶段（rasterization stage），光栅化阶段就是将集合处理阶段的顶点数据，转换为我们实际显示需要的像素化的数据，他做的事情就是将找到各个三角形（三角形片元）需要的像素，然后传给下一个阶段
   4. 像素处理阶段（pixel processing stage）,这个阶段就是决定每个像素具体要显示什么颜色，并且可能会计算深度测试判断他是否可见，它还会做一些例如说逐像素的计算，例如说混合颜色等。

   每个阶段都是一个独立的流水线。

3. 一些概念定义

   1. FPS (frame per seconds)
   2. HZ(notation for 1/seconds)

总体而言，这个流水线的结构分成了四个部分，而之前常看见的，顶点着色器=>图元装配（shape assembly）=>几何着色器(geometry)=>=>光栅化（rasterization ）=>测试与混合（test and blending）=>片段着色器（fragment shader）=>光栅化（rasterization ）这个流水线则是上述四个部分的细化，例如前面的顶点着色器开始就是几何处理阶段，和片段着色器就到了最后的像素处理阶段，这也是为什么逐像素光照效果更好的缘故

### 2.2 应用阶段

​	应用阶段做的事情是开发者可以控制的，这种直接运行的程序。开发者在这里的操作会影响整个渲染过程。例如可以在应用层就可以减少需要渲染的三角形的数量。这个阶段可以做的事情有如下几个例子：

1. compute shader，我们可以将一部分计算交给gpu来运算，利用的是gpu强大的并行运算能力。例如说在戴森球计划里面，就大量的运用了这一技术
2. rendering primitives ,应用阶段我们将会将需要渲染的数据填充给几何处理阶段的程序，在性能优化阶段，我们常说的减少drawcall就是这个道理，在应用阶段我们会将需要渲染的点，线，三角形数据传递给下一个阶段。（CPU计算通常是并行的，而渲染管线的计算也通常是并行的，这意味着可能可以通过并行阶段同时feed每一个阶段）
3. 碰撞检测，应用层将会对对象之间的碰撞检测进行计算，这也会影响到某些输入输出
4. 一些优化算法，例如剔除算法（particular culling）

### 2.3 几何处理阶段

几何处理阶段，GPU会处理逐三角形（网格）和逐顶点的操作，这部分的内容主要包括有顶点着色，投影，裁剪，屏幕映射几个放米娜

#### 2.3.1顶点着色

顶点着色主要有两个大的作用一是计算顶点的位置和确定程序需要作为顶点输出的部分，例如输出法线和纹理坐标，传统来说，大部分阴影的计算是通过将光照应用到每个顶点的位置和法向量然后只在顶点数据中存储颜色信息。这部分颜色之后将会在三角形上进行插值计算。因为这个原因，这种可编程的顶点渲染被称为顶点着色器。

顶点着色器通常会计算一些更通用的和顶点相关的数据和信息，例如顶点着色器可以对一个对象进行动画运算。

1. 顶点位置的计算方式，首先我们通常需要一组坐标，在显示到屏幕的过程中，一个模型会被变换到各种不同的坐标系或者空间。
   1. 最初，模型的坐标都是基于他自身的模型空间，每个模型都有一个model transform 这样它才能够定位它自己。由于这个的存在，模型才能在同一个场景下拷贝出相同的结果。
   2. 经过转换，模型会被转换到唯一的世界坐标系中。
   3. 接下来，我们还需要将他转换到照相机的坐标系下，因为只有被摄像机看到的东西，才会被显示。摄像机在世界坐标系中也会有一个坐标来定位。视觉变换矩阵用于设置摄像机位于原点，并且面向Z轴的负方向，这是Y轴向上，而X轴向右，而有的会面向Z轴的正方向，（DX和OPGL），这个坐标系我们称之为view space ,eye space或者camera space
2. 渲染的时候，只渲染形状和位置是不足够的，整体模型的外观也是很重要的。比如光的影响，材质的影响。因此顶点处理还会处理一些额外的内容，比如法向数据，颜色数据，纹理坐标等。最后顶点着色的结果会被送去光栅化阶段进行插值处理，而这个处理总体而言会比像素处理效果差一些
3. 顶点着色的过程还会进行一个投影的处理，投影方式包括了正交/平行投影和透视投影。而投影的方式，这两种方式都可以通过一个4*4矩阵来进行计算。经过投影之后，模型可以说进入了裁剪坐标系中。而顶点着色器的输出结果都得在这个坐标系中，这样裁剪才能正常工作。投影过程中，Z值会被存储到Zbuffer中，这个时候就完成了3D转2D的转换

#### 2.3.2 额外的顶点处理

有些顶点着色处理有几个了额外步骤，平铺。几何着色，输出。当然这个很依赖与GPU，并且不是必须的操作。

1. tessellation: 这个操作的作用是，确定一个object合理的三角形数目，例如，一个足球模型，如果你使用过多三角形来描述它，但是场景中它很远，就是一种浪费计算时间，而这个处理就会选择一个合适的数量的三角形来完成一个更好的表面。顶点着色之后，我们获取到的其实是一系列顶点数据，而在tessellation过程中，它包括了几个步骤，包括了hull shader,tessellator domain shader等等，这些会将顶点坐标处理为新的一组数据，用于生成三角形，这样就能确定具体要显示多少个网格的三角形
2. 几何着色器 geometry shader:几何着色器更为普遍，几何着色器的常见操作例如说模拟一些图像效果例如烟火爆炸，粒子效果等，一个粒子效果，如爆炸，经常被表示为一个点，而几何着色器会将其转换为一个眠，通过两个三角形完成，然后使其面对摄像机，这样子就更方便的处理粒子效果 
3. 流式输出stream output: 这个部分让我们将GPU作为一个简单的几何处理器，在这个阶段那我们可以输出这里的数据用于额外用途，这些数据可以被CPU或者后面的GPU操作使用到，这部分内容也会用于粒子系统

这三个阶段的顺序为tessellation,几何着色，流式输出，而这三个阶段都是任意可选的

#### 2.3.3 裁剪

裁剪阶段，我们会将不需要渲染的部分给裁减掉，从计算来说，我们会将顶点数据和裁剪矩阵进行计算，从物理角度来说，这是使用一个6面的方块进行了裁切，同时，我们还可以定义一个额外的裁切平面进行裁切

在使用过裁剪之后，部分在视野之外的对象会经过额外的处理，会将在外的部分去掉，然后替换为新的顶点数据

#### 2.3.4 屏幕映射

经过裁剪之后，图像还是处于3D坐标系上，而要显示，则还需要映射到屏幕上

X,Y,Z都会被映射为一个新的区间【x1,x2】[y1,y2] 【z1,z2】(-1,1)/(0,1)

接下来我们会将坐标和像素对应，对应方式很简单，像素的中心为0.5(d=floor(c),c=d+0.5)

DX和opengl略有不同

### 2.4 光栅化

光栅化阶段，主要包括了图元装配（三角形setup）和三角形遍历，光栅化的过程主要是确定一个像素是否属于一个三角形

#### 2.4.1 三角形setup

在这个部分，会计算三角形所需要的数据，这些数据会在遍历三角形中所用到，包括了会在像素处理中用到的数据

#### 2.4.2 三角形遍历

在这个阶段，每个被三角形所覆盖的像素都会被检查，并且一个片段（用于片段着色器）将会在这个阶段中生成。每个三角形片段的生成过程会被称为三角形遍历。每个三角形都是通过顶点数据然后通过插值算法生成的。

### 2.5 像素处理

像素处理阶段所处理的像素，是和前面的数据相关联的。这个部分的内容主要分为两个部分，一是像素着色，二是混合

#### 2.5.1 像素着色

像素着色阶段，使用前面阶段计算完成的插值计算后的数据，计算的结果是一个或者多个颜色，然后会传递到下一个阶段，和图元装配和三角形遍历，这部分内容是使用可编程的GPU核心，因此，这部分的内容可以通过片元着色器来定制化。这部分的核心功能是纹理，纹理映射的意思就是将一张图映射到渲染对象上，

#### 2.5.2 混合

每个像素的信息都储存在颜色缓冲中，这是一个颜色矩阵。混合阶段主要负责将像素着色阶段的片段颜色和已经保存在颜色缓冲中的数据混合。这个stage也称作ROP（raster operations pipeline/Raster Operation/ROP-Unit/光栅化处理单元/渲染输出单元）,这个阶段不是完全可编程的，但是高度可配置的。

这个部分还负责处理可见性，即处理什么时候整个场景需要渲染。对于绝大部分图形硬件来说，这是通过Z-BUFFER来处理的，z-buffer和颜色缓冲是有相同大小的。Z值代表着离摄像机的远近，因此，z越大，离摄像机就越近。一个z值较小的像素则不会被渲染。然而这个算法是比较简单的，因此不能用来对半透明对象进行计算，因此半透明对象需要一个特别的算法，并且是需要从后往前进行渲染，需在最后来处理这个。基础z-buffer的弱点就是半透明运算。

α通道和颜色缓冲有关，它保存有每个像素的透明度，（old api）它还被用来做像素的可选性剔除，现在这个剔除操作被插入到片段着色器中，任何一个计算都可以触发一个剔除。α测试能用于保证一个完全透明的片段不影响整个z-buffer

*模版缓冲（*stencil buffer*）或印模缓冲* 是另外一种数据缓冲，和深度缓冲类似，它为屏幕上的每一个像素保存一个8位的无符号整数，从片元着色器出来的数据，在进入到深度测试之前，会进行一个模板测试，我们可以通过这个部分来控制进入到颜色缓冲和z-buffer的数据，从而做到丢弃或者保留某些像素的功能。模板缓冲对于实现某些特效特别有用，。

所有这些功能统称为混合操作，他们就是最终得出三角形的最终颜色的操作。总体而言，该阶段只有有限的可配置的操作，有一些API能够支持可编程的混合能力

帧缓冲（framebuffer）就是由所有上述系统的buffer组合而成的。当所有图形都通过了光栅化阶段，并显示到屏幕上时，他显示的是颜色缓冲中的内容，双缓冲在显示中使用上了。双缓冲的作用就是一个正在显示的前缓冲和一个随时准备替换内容的后缓冲，这部分的替换通常是在vertical retrace中进行替换的

### 2.6 总结整个流水线

==========================

## 3.图形处理单元（Graphics Processing Unit）

（直接翻译）传统上来说，图形加速会在显示三角形需要对每个像素进行插值的时候开始。包括了访问图像数据并将纹理映射到表面上。为插值运算和深度测试添加专门的增加了包含有内置可见性检测功能的硬件。因为频繁的使用，这些流程会交给专门的硬件，这就是GPU。GPU通过专注于一些高并发的任务来提高他们的速度，现在更需要了解的是GPU如何为它的可编程shader进行并发、

​	3.3解释了shader是怎么工作的，现在你需要知道的是，一个shader核心是一个负责做某些相对独立的过任务的处理器。比如说将一个顶点位置转换到一个屏幕坐标系，或者计算一个被三角形覆盖的像素的颜色。在成千上万的三角形被输送到屏幕显示的每一帧的同时，会有大量的shader调用。

​	延时是每个处理器都必须面对的问题，访问数据是需要花费一定的时间的，一个最基本的考虑延迟的方向是考虑当信息和处理器的传输距离越远，处理器需要等待的时间越长，。存储在内存中的信息会比在本地寄存器中的信息花费更长的时间去访问。关键点就在于数据传输的过程会降低性能，因为处理器会空转。

### 3.1 数据平行结构（data parallel architectures）

**CPU**: 为了避免处理器空转？（stalls）有很多种策略都被使用了，CPU被优化来处理更多的数据结构和更大的代码量，CPU可能有多个处理器，不过大部分都使用串行方式运行，受限制的SIMD（单指令多数据）向量处理是一个小小的例外，为了让延时的影响最小，大量的CPU由本地缓存，包含有可能在接下来会使用的数据的内存组成，CPU也会通过非常聪明的例如分支预测（branch prediction）指令重排（instruction reordering)，寄存器重命名（register renaming）和缓存预取（cache prefetching）

**GPU**: GPU使用不同的优化方法。大部分GPU的芯片是专用于某个大型的称为shader cores的大型处理器的。GPU是流式处理器，大量的相似的数据会依次被处理。由于这些数据的相似性，例如一组顶点或者像素，GPU可以使用大规模并行的方式处理这些数据。另一个非常重要的因素是这些调用会尽可能的独立，使得两个相邻的调用之间不会有需要共享的信息，也不会共用一个可写的内存地址。这些规则有时候会被打破，用来支持某些新的并且有用的功能，不过这些例外会带来的代价是潜在的延迟，因为有时候会让一个处理器等待另外一个处理器完成。

通过定义可处理数据的最大速率来对GPU吞吐量（through put）进行了优化。但是这种快速的处理还是有消耗的。当更少的芯片被用于保存内存和控制逻辑，在每个shader core中间的延迟通常都会被认为是高于CPU的

假设一个网格光栅化后有2000个像素包含有片段（fragment）（此处直译）需要处理（片元着色？），一个像素着色器程序将要被调用2000次，而假设这个GPU只有一个shader处理器，这个处理器开始处理这个片段。这个处理器需要对寄存器中的数据做一些算法运算，而寄存器是快速访问的，因此没有任何空转（stalls）,接下来，着色处理器接着处理下一个指令例如纹理映射，而纹理则是一个完全分隔的资源，并不是之前的像素处理中的任何一部分数据，而内存读取会耗费成百上千的时钟周期，而这段时间内GPU将什么都做不了，一直等着纹理数据进行返回。

为了优化这一部分内容，我们可以给每个片段（fragment）的本地寄存器一点空间来保存,因此在进行纹理获取的时候，shader处理器可以进行切换并运行另外一个片段的运算。这个切换是非常快的，而第一个和第二个片段都不会受到影响，然后就是第三个，第四个，最终2000个片段都被处理了，而这时处理器已经成功获取了纹理颜色并且可以使用了，这时候就开始进行下一步运算，和之前一样，这一步也会一直运算直到需要等待或者整个程序运算完成。并行运算将会大大降低一个一个的完整的运算

在这种架构中，延时被GPU切换去其他片段进行运算的行为"藏"起来了，GPU使用这种思想的跟进一步的设计，一个被称为SIMD（single instruction multiple data）单指令多数据的结构，这种结构安排在固定数量的着色程序中，以锁步（lock-step）的方式执行相同的命令。SIMD的优点包括和使用独立的逻辑发送单元相比在处理数据和切换上更加节能省硅？？。如果将我们刚刚的例子中的2000个片段放到现代的GPU当中去，每个片段的像素的着色指令被称为是一个线程，和GPU的线程不同，它包含了一部分输入着色器的值的内存，和着色器运行中需要的着色器空间一起。使用同一个着色器的线程会被组合成一个组，在NVIDIA中被称为一经纱（warp），而AMD中称为波前（wavefront），这些波会被根据GPU的着色核心安排运行的时间，使用SIMD结构运行，每一个线程都会被映射到SIMD lane上

假设有2000个片段需要着色，而我们的NVIDIAGPU包含有32个线程，那么我们产量（yield）就是2000/32 = 62.5warps，这意味着我们需要63warps来完成渲染（是否和纹理最好和2的n此方有关系？），其中一波将会是半空的，一个波的运行很像是我们之前的单个处理器的例子。着色程序锁步的在所有32个处理器上同时运行，当遇到一个内存获取事件时，所有线程都会遇到这个事件，因为所有线程都在执行相同的指令，而这时这一波将会停下来等待数据的获取，然后当前运行的波就会切换到另外一个32个线程的warp去，这个切换将会非常的快，每个线程中的数据不会因为warp的切换而被影响到。每一个线程都有他独立的寄存器，而每个warp都会记录哪一个指令正在被执行，切换到一个新warp只会影响指向不同线程来执行指令的核心。而这不会有间接成本

![shader_process](.\shader_process.png)

着色器程序的结构是非常重要的会影响效率的特性（是否写shader的时候将一些操作放到后面可优化？，更少创建东西来存数据能否优化？），主要的因素是每个线程使用的寄存器数量，当我们有更多的寄存器被着色器程序所需要，那我们就会有更少的线程，因此更少的warp能够存在于GPU中，那么延时就很难被平滑度过，GPU中存在的warp数量被称为occupancy值，这个值越大，意味着有很多warps可以被处理，那么就不会有闲置的处理器，较少的占用率会导致更差的性能，内存访问的频率也会影响有多少延时需要平滑度过。

另外一个影响整体性能的特点是动态分支，被__if__和__while__所影响（shader不要写太多ifwhile），如果在所有的线程中if的结果都是相同的，那处理器可以不用担心另外一个分支，但是如果某一些线程，或者某一个线程走了另外一个分支，那么warp必须要执行所有的分支，获取到一些不需要的结果，。这被称为线程分歧，如果有一少部分线程需要做一个循环或者执行一个if语句，而其他同warp的线程不需要，这会让他们在运行的实践中被闲置

所有的GPU都有实施这些结构的理念，这样使得GPU整体成为了一个被严格限制但是提供了大量的计算力的系统理解这个系统是怎么运行的有助于程序员完成一些更有效率的shader。

### 3.2GPU流水线概览

GPU实现了概念上的图形处理，光栅化，像素处理，这部分流程被分成了几个具有不同程度可配置或可编程的硬件阶段。下图中根据可编程或可配置的方式显示不同阶段的颜色编码 ，注意这些物理阶段和C2中的功能化的阶段有些许不同

![pipeline](.\pipeline.png)

我们在这里描述的是GPU的逻辑模型，这部分会给你暴露API让你使用。这部分逻辑化的流程是由供应商决定的。一个程序可能会被拆分成不同的部分然后被不同的子单元所运行，或者是通过一个完全独立的通道运行，逻辑模型可以让你知道什么会影响性能，但是不应该将它和GPU真正执行的流水线混淆

顶点着色器阶段是一个完全可编程的阶段，这部分用于执行几何处理，。几何着色器也是一个完全可编程的阶段，他会在一个图元（点，线，三角形）的顶点上执行，它能够用于执行pre-primitive shading operation.用于销毁图元或者重新建立模型。镶嵌（tessellation）阶段，和几何着色器阶段都是可选的，，而且不是所有硬件都能支持他们

裁剪，三角形装配，和三角形遍历阶段是被固定功能的硬件所完成的。屏幕映射阶段则是被窗口大小和视口设置所影响，它会在内部实现一个简单的缩放和重定位。像素着色阶段也是完全可编程的（片元着色？）。而尽管合并阶段是不可以编程的，但是它是高度可配置的，而且可以被设置做很多操作，。合并功能阶段主要负责修改颜色，z-buffer，混合，模板操作，以及其他的任何和输出有关的缓冲。像素着色也会和合并阶段一并执行，它们共同组成了第二章所说的像素处理阶段

随着时间的演化，GPU流水线逐渐的从硬编码的方式往提升灵活性和可控制性，这部分介绍的可编程的着色器阶段是这个变化的和新阶段，下一个部分的主要内容则是这些可编程阶段的共性

### 3.3 可编程渲染阶段

现代的着色程序都使用相同的着色器设计，这意味着顶点，片元，几何，镶嵌相关的着色器都使用一个类似的编程风格。在内部，他们有相同的ISA(instruction set architecture)指令集架构。一个有这种模式的处理器被称为普通渲染核心，这种gpu被称为标准着色器架构的GPU。这个架构的背后的想法是着色器实在一定的规则下运行的，而GPU可以按照它认为合适的方式分配他们，例如，一组包含着小三角形的网格会需要比一个大的片但是只被两个三角形组成的更多的顶点着色器处理，GPU有分开的的顶点和片元着色器池可以让意味着理想上可以让每个核心都保持着忙碌的工作。当使用通用的渲染核心的时候，GPU可以平衡这两者。

后面内容会讲到整个着色器编程模型

基础的数据结构是32位的单精度浮点数和向量，尽管向量是渲染代码的一部分，并且并没有在硬件中如刚刚说的所支持。在现代GPU中，32位整数和64位浮点数也是原生被支持的。浮点数向量通常包含有位置(xyzw)，法向，矩阵行，颜色(rgba)或者纹理坐标（uvwq）.整数通常被用来表示计数器，指数，位掩码。集合数据类型例如结构体，数组，还有矩阵也都被支持

一个drawcall 包含了绘制一组图像的API，因此它会让图形渲染管线开始执行，并进行着色。每一个可编程的着色阶段都有两种输入，uniform输入，包含有在整个drawcall中都保持不变的值(在draw call之间可以变)，以及varying输入，来自于三角形顶点的数据或者是光栅化的数据。问题数据是特殊类型的uniform数据，它之前是用于将一个有颜色的图片应用到表面上，但是现在可以看做是一组大量的数据

底层虚拟机提供了一系列独特的寄存器用于不同种类的输入和输出，给uniform用的常量寄存器比其他varying的输入输出的寄存器要多，这是由于varying的输入和输出在每个顶点或像素之间需要独立的存储，所以他会有一个自然地限制他们有多少。而uniform输入存储了一次之后就会在一次drawcall中在所有顶点和像素之间公用。虚拟机同时也含有通用意图的临时寄存器，他们用于提供暂存空间

![Shader_virtual_machine](.\Shader_virtual_machine.png)

在现代GPU中，运行的过程大都相似，着色语言揭露了这些操作的共性。包括了操作符*，+，其他的例如一些函数atan(),sqrt(),log(),还有一些其他的，都被GPU所优化。函数在某些复杂操作中同时也存在，例如向量的的正则化和反射，矩阵平移等

流控制这个术语指的是通过分支指令来对代码的执行进行改变。和流控制相关的指令被用于实现高等编程语言中的一些特性，例如“if",”else“。着色器支持两种类型的流控制，静态的流控制分支基于uniform类型的输入，这意味着这个流的代码在整个drawcall中是常量化的，静态分支的主要好处在于可以允许同一个着色器在各种不同的情况下使用（例如各种光照）。因为调用采用相同的代码路径，所以这里没有线程发散。动态的流式控制依赖于varying的输入，这意味着每个片元可以独立的执行代码。这笔静态的流式控制要更加强大，但是会消耗性能，尤其是在着色器调用之间，选择的代码流不确定的的状态下





### 3.5 顶点着色器

顶点着色器是GPU流水线中的第一个部分，这也是直接开发者控制下的第一个阶段，在这个阶段之前的数据操作是没有意义的。在DX中被称为输入装配（input assembler）中，一部分数据流会组合到一起，形成在流水线中传递的一组三角形和图元。打个比方，一个对象可以被一组顶点数据和一组颜色数据所表示，而这个输入装配中，它会使用带有颜色数据的顶点（vertices）产生这个对象的三角形（或者是点，线）。而另外一个对象也可能会使用同样的位置数据（这个对象会有一个不同的模型变换矩阵）以及不同的颜色数组来表示。在输入装配中，也会用来做实例化，这就允许在每个实例中使用不同的数据多次绘制一个对象，仅仅只需要一次drawcall。

一个三角形网格是被一组顶点表示的，每个顶点都和模型表面上的坐标所关联，出了坐标之外，还有一些额外的属性，例如颜色或者是纹理坐标。表面法向也是在网格中的顶点中所定义的，这个看起来会比较奇怪。数学角度说，每一个三角形都会有一个定义好的表面法向，在着色中直接使用三角形的法向会有一定的意义。但是在渲染中，三角形网格通常被用来表示一个潜在的曲面，而顶点法向则用来表示表面的方向而不是三小型网格本身，下图显示了两个三角形的侧面图，用来表示一个曲面，一个平滑的曲面和一个尖锐的面。

![triangle_meshes](.\triangle_meshes.png)

顶点着色器是第一个处理三角形网格的的。描述三角形形成的数据对顶点着色器是不可用的。就像它的名字说的那样，他只处理输入的顶点。顶点着色器提供了一个用来修改，生成，或是忽略和三角形的顶点相关联的值（如颜色，法向，纹理坐标，位置等）的方法。通常来说，顶点着色器将顶点从模型空间变换到了齐次裁剪空间。一个顶点着色器最少都应该输出这个位置数据。

顶点着色器会处理每一个传进来的顶点，然后接着输出一组在三角形或者是直线上进行插值过后的值。顶点着色器既不能产生顶点，也不能摧毁顶点，而通过一个顶点产生的值并不能传递到另外的顶点上去。因为每一个顶点都是被独立处理的，不管有多少着色处理器，他们都能够对输入的顶点数据流并发的进行处理

 通常情况下，输入装配代表的是顶点着色器执行之前的过程。这里有一个表现物理模型和逻辑模型的差异的例子。物理上来说，获取数据来生成一个顶点可能在顶点着色器中处理，驱动会在背后默默地将每个着色器使用正确的指令进行预设值，而这个操作程序员是不知道的

后面的章节中聊到了顶点着色器影响的其他部分，例如说对动画关节和轮廓渲染进行的顶点混合，其他用法包括

* 对象生成：只创建一个网格一次，并通过顶点着色器对其进行变形
* 角色的身体和面部动画，通过使用skinning and morphing 计数
* 程序上的变形（Procedural deformations），例如旗帜，衣服，水的流动
* 粒子创建，通过传递退化的网格（degenerate meshes）到流水线的以下一段，并且让这些粒子有被给予需要的空间
* 光学变形（lens distortion），热雾（heat haze），水涟漪（water ripples），页面卷曲（page curls）和其他效果，通过使用整个帧缓冲的内容作为一个纹理对一个屏幕对齐网格进行程序变形  
* 应用地形高度场（terrain height fields），通过使用顶点纹理获取

![figure3.8](.\figure3.8.png)

顶点着色器的输出可以通过不同的方式被使用。常规的方式就是每一个实例的图元，例如三角形，被生成然后光栅化，然后将像素传递到片元着色器中。在某些GPU中，这些数据也能被传递到镶嵌阶段或者是几何着色器阶段亦或是在内存中保存。

### 3.6 镶嵌阶段（曲面细分）

镶嵌阶段允许我们渲染弯曲表面。GPU的任务是取每个表面的描述并将其转化为一组可以用于代替表示的三角形。这部分阶段是在DX11中被额外添加的GPU阶段，也被OPGL4.0和OPGLES3.2所支持

使用镶嵌阶段有很多优点，曲面描述通常来说比提供相应的三角形描述要更加细致紧凑。除开空间的节省以外，这个特性也会避免CPU和GPU之间的总线（GPU带宽？）成为性能的瓶颈，例如当我们要渲染一个每帧都会变化的动画角色或对象。这些表面可以通过有正确数量的三角形来描述从而能够更加有效率的进行渲染，例如，一个在远处的球只需要较少的三角形，而一个近处的则需要更多。这个可以控制细节等级的能力可以让程序能够更好的控制它的性能。例如，一个低质量的网格可以提高帧率。模型通常来说被是由平面组合而成，这些平面会被转换为对应的网格，然后通过变形成为需要的样子，亦或者他们能够被镶嵌以便能够更少的进行着色运算。

镶嵌阶段一般来说被分为三个部分，使用dx的术语来说，这部分分为hull shader,tessellator domainshader 三个部分。在opengl中，hull shader对应的（tcl？），tessellation evaluation shader,这部分是更加可描述的。固定功能tessellator被称为图元生成器（primitive generator）

下图中说明了细分和tessellate curves and surfaces .对每个阶段，我们给与了一个简短的介绍。

![fig39tessellation](.\fig39tessellation.png)

在最开始，输入到hull shader的输入时一个特殊的图元patch，这部分是由一部分定义了细分表面的控制点，Bezier patch ，或者其他类型的曲边元。Hull shader有两个功能，首先，它告诉了tessellator有多少三角形需要被生成，并且它们的设置是什么。然后，它再每一个控制点上都开始执行操作。hull shader也能修改传入的patch的描述，按照预期添加或删除控制点。hull shader输出它的控制点集和tessellation control data 给下一步的domain shader

tessellator 是渲染管线中固定功能的一个阶段，它只会在tessellation着色器中使用。它的任务是添加一部分新的顶点给domain shader使用。Hull Shader 会传递关于需要怎样的镶嵌表面类型的tessellator信息，例如三角形，等值线，四边形等。等值线是一组线条组，有的时候会被用来做毛发渲染。另外一个hull shader所传递的重要信息则是tessellation factors（在opgl里面是tessellation levels）。他有两种类型，内外边缘。outer factor 确定每个外边缘的分割程度 ，而inner factor 则确定多少镶嵌操作在三角形或者四边形中发生。一个提高tessellation factors 的例子在图3.10中表现了。通过独立的控制，我们可以调整曲面的表面来匹配镶嵌，而不管内部是怎么镶嵌的。边缘匹配避免了裂缝或者xxx.顶点被指定重心坐标，它是指定所需表面上每个点的相对位置的值  

![3.10](.\3.10.png)

尽管这个系统看起来十分复杂，但是它是被设计成这个模式以便使操作更加有效率，而且每一个着色器都能很简单。传递到hull shader中的patch通常情况下会有很少的或者没有修改，这个着色器也可能使用patch中的估计距离或屏幕大小，以计算飞行中的镶嵌因子，如地形渲染。或者Hull shader可能会简单的传递所有程序计算或者提供的patch中的一组固定的值。tessellator执行一个复杂但固定的生成顶点的过程，给出它们的位置，并指定它们构成什么样的三角形或直线。这个数据放大操作是在着色器外执行的，以提高计算的效率。domain shader 为每个点生成重力坐标并在patch的评估方程中使用这些坐标来生成位置，法向，纹理坐标，以及其他的顶点信息，图3.11就是例子

![pic3.11](.\pic3.11.png)

### 3.7 几何着色器

几何着色器可以将图元转换为另外一个图元，这是在镶嵌阶段没法完成的。举个例子，一个三角形网格可以通过让每个三角形创建线边来转换到线框视图，另外，这些线可以被面向观察者的四边形所替换。所以制作一个边缘较粗的线框渲染？（迷惑），几何着色器被添加到硬件加速图形管线在DX10,它的位置是在镶嵌阶段之后，并且它的使用是可选的。

几何着色器的输入时一个对象和它的相关的顶点，这个对象是被三角形，线段或者是一个简单的点所组成。额外拓展的图元可以被几何着色器所定义和处理。特别是，可以传入三角形外的三个额外顶点，折线上的两个相邻顶点也可以使用 。图3.12中可以看到。在DX11和shadermodel5.0,你能够传入更多精心制作的多达32个控制点的patch。 也就是说，在patch生成过程中，镶嵌阶段的效率更高

![3-12extrapoint](./3-12extrapoint.png)

几何着色器处理图元并且输出零个或者更多的顶点，他们会被当做点，线段或者是三角形所对待。请注意，注意，任何输出都不能由几何着色器产生。通过这种方式，可以通过编辑矢量、添加新图元和删除其他图元来有选择地修改网格。

几何着色器被被设计为修改输入的数据或者产生有限数量的拷贝.举个例子，一个用法是用来产生六份变换后的拷贝来同时表现一个立方体的六个面，同时它也能用来有效率的生成层级阴影贴图给高质量的阴影生成。另外一个算法可以发挥几何着色器的优势，包括从顶点数据中产生可变尺寸的粒子，为毛发渲染生成鳍状，为阴影算法找到对象的边。

DX11为几何着色器添加了实例化的能力，这样几何着色器可以再任意给与的图元上运行很多次。在OPGL4.0，这通过调用计数来进行指定。几何着色器也能够输出最多四个流，一个流可以传送数据到接下来的渲染流水线。所有流都能可选择的被输入到输出流的渲染目标中。

几何着色器被确保了和输入图元相同的输出顺序，这个会影响到性能。因为如果一部分着色核心平行的运行，结果必须被按照顺序保存。这和其他因素都不利于几何着色器在一个单一的调用中被用来复制或创建大量的几何图形 

当一个draw call被执行，在GPU流水线中只有三个地方可以创建工作：1,光栅化，2.镶嵌阶段，3几何着色器。在这三个阶段中，几何着色器阶段的行为是最难以预测其资源和空间消耗的，这是因为它是完全可编程的。在实践中，几何着色器经常没有什么做作用，并且和GPU的能力不匹配。在某些移动端设备中，它被在软件中实现，那里它的使用被不推荐

#### 3.7.1流式输出

GPU流水线的标准使用方式是传输数据经过顶点着色器，然后光栅化其输出的三角形，然后将这部分的结果交给片元着色器处理。曾经数据通过管道传递，无法访问通过管道传递的中间结果 。流式输出的的点子是在shader4.0模型中被踢出，当顶点被顶点着色器处理完毕，（可选的，镶嵌阶段或者几何着色器阶段），它们的输出，一个数组，出了被输出到光栅化阶段，可以被输出到一个流中。实际上，可以完全关闭光栅化阶段，然后将流水线纯粹用作非图形流处理器。这个方式下被处理过后的数据可以在整个流水线阶段被输出回来，因此可以允许迭代处理。这种类型的操作可以再模拟流水或者其他粒子特效时特别有用。他也能用在模型的皮肤渲染然后让这些顶点能够重用。

流式输出返回的数据只能以浮点数形式，因此他会有明显的内存处理，流失输出对图元有作用，但是不直接作用于顶点，如果网格被输出到了流水线的下一个阶段，每一个三角形都会被生成他独有的三个顶点输出的集合。原有网格中所有共享的顶点都会丢失。因此，更典型的用法是将顶点作为点集原型通过流水线传递。在OPGL中，流式输出阶段被称为transform feedback，因为它的用途主要集中于顶点变换然后返回给其他后面的操作使用。图元保证按照输入的顺序发送到流输出目标 ，这意味着顶点的顺序也会被固定

### 3.8 像素着色器

在顶点，镶嵌，几何渲染完成了它们的操作之后，图元被裁剪然后被装配进行光栅化。和在之前的章节里面说到的那样。流水线的这部分是相对固定的，即在它的处理过程中，它是不可编程的，但是某种程度上是可配置的。每一个三角形都被遍历以便确定它覆盖了哪些像素。光栅化也会计算三角形覆盖每个像素的单元面积。三角形中部分或完全重叠像素的部分称为片段 。

 三角形顶点的值，包括在z-buffer中用到的z值，都被插值到三角形表面的每个像素。这些值被传递到像素着色器，这个处理片段的着色器中。在OPGL中，这个着色器被称为片段着色器。顶点和线段也同样会产生他们所覆盖的像素的片段

像素着色器规定了三角形插值操作的类型。通常情况下，我们使用透视校正插值（Perspective-Correct Interpolation），因此像素表面位置之间的世界空间距离随着物体在距离上的后退而增加 。一个例子是渲染铁路分岔延伸到地平线 。在铁轨较远的地方，枕木之间的距离越近，因为每一个连续像素接近视界的距离更大。另外一个插值选择是可用的，例如空间插值（screen-space interpolation），其中不考虑透视投影 。DX11给与了更多关于何时以及如何进行插值操作的控制接口

在编程术语中，顶点着色程序的输出，通过三角形(或线性)插值，有效地成为像素着色程序的输入。 随着gpu的发展，其他输入也被暴露出来。 例如，片段的屏幕位置在shader模型3.0及以上的像素着色器中是可用的，同样三角形的哪边是可见的也是一个输入片段。 这个知识对于在一次绘制（a single pass）中同时渲染三角形的正面和背面的不同的材质是很重要的

有了输入，通常像素着色器计算并且输出片段的颜色。它也能计算透明度值和随意修改他的Z值。在混合的过程中，这些值会被用来修改像素中存储的值，光栅化阶段中所产生的深度的值也能够被像素着色器所修改。模板缓冲区中的值通常不会被修改，而是会被传递到混合阶段，DX11.3中允许了着色器修改他的值。在shademodel4.0中像是计算和aplha测试已经从混合阶段移动到像素着色计算阶段

最初，像素着色器只能输出到最终显示的混合阶段，。随着时间的推移，一个像素着色器可以执行的指令数量大大增加。这个增加导致了一个想法，多重渲染目标（multiple render targets）。不同于仅仅输出颜色和z-buffer作为像素着色程序的结果，可以为每个片段生成不同的值集并保存到不同的缓冲区，每个缓冲区称为渲染目标。渲染目标总体上都有同样的x和Y维度。有一些api允许了不同的大小，但是被渲染的区域的大小会是最小的。一些架构要求渲染目标都有相同的位深度，甚至是相同的数据格式（如果可能的话）。取决于不同的GPU，渲染目标同时可以有四个或者是8个

即使有这些限制，mrt功能仍然是更有效地执行呈现算法的强大帮助  。一个单一的渲染pass可以在一个目标中生成彩色图像，在另一个目标中生成物体标识符，在第三个目标中生成世界空间距离。这个能力也催生了另一种类型的渲染技术，称为延迟着色（延时渲染？），它的可见性和着色是在单独的通道中完成的。在第一个pass中保存了对象的位置和材质信息。成功的pass可以有效率的引用光照或者是其他特效，

像素着色器的限制是通常情况下它只能只在交给它的片段位置写入渲染目标，并且不能读取相邻的像素的当前的结果。也就是说，当一个像素着色程序执行时，它不能将它的输出直接发送到相邻的像素，也不能访问其他像素最近的变化。相反，它计算的结果只影响它自己的像素。但是这个限制并没有听起来的那么严格，。一个在一个pass中输出的图片可以在下一个pass中被像素着色器获取到它的任何数据。邻接的像素也能被使用图像处理的技术所处理

对于一个像素着色器不能获取或是影响邻接像素的结果的规则有一些例外。其中一个就是像素着色器可以在渐变或导数信息的计算过程中，立即访问相邻片段的信息(尽管是间接的)。像素着色器提供了任意插值值沿x和y屏幕轴每像素的变化量，这些值对于各种计算和纹理寻址都很有用。这些渐变对于纹理过滤等操作特别重要，在这些操作中，我们想知道一张图像对一个像素的覆盖程度。所有现代gpu都是通过2x2分组（被称为一个quad）处理片段来实现这一特性的。当一个顶点着色器请求一个渐变值的时候，返回相邻片段之间的差值。参考图3.15.![fig3-155](.\fig3-155.png) 

一个统一的核心具有访问邻近数据的能力——在相同的warp中但是保持在不同的线程中——因此可以计算像素着色器中使用的渐变 。这种实现的一个后果是，在受动态流控制影响的部分着色器中，渐变信息不能被访问，举个例子，一个“if”判断或者是需要进行多次迭代的循环，。一组中的所有片段必须使用相同的指令集进行处理，以便所有四个像素的结果对渐变计算都有意义。这是一个即使在离线渲染系统中也存在的一个基本限制

DX11引入了一种可以允许对任意地址写操作的buffer，乱序访问视图（可读写）（UAV unordered access view ）,最初仅为像素和计算着色器，在DX11.1中，访问UAV被拓展到了所有shader。在opgl4.3中，称它为shader storage buffer object（SSBO）。两个名字都是用自己的名字来解释它的用法。像素着色器是按任意顺序平行运行的，这个buffer则在他们之中共享

为了避免数据争用（data race）的情况，我们经常需要一些一些机制。数据争用是指两个着色程序都在“竞争着”影响某些值，这样可能会导致不可预期的结果。举个例子，如果一个像素着色器的两次调用试图在几乎同一时间添加相同的检索值，则会发生错误。两者都将检索原始值，都将在本地修改它，但无论最后哪个调用写入其结果，都会抹去另一个调用的贡献，只会发生一次添加。GPU通过提供着色器可以访问的专用原子单元来避免这个问题。然而，原子性意味着一些着色器可能会在等待访问其他着色器读取/修改/写入的内存位置时停顿

虽然原子性避免了数据危害，但许多算法需要特定的执行顺序。举个例子，你可能想画一个更远的透明蓝色三角形，在用一个红色透明三角形覆盖它，然后将红色和蓝色混合在一起。一个像素被两个像素着色器调用是可行的，每个三角形都有一个独立的着色器，以这样一种方式执行，红色三角形的着色器在蓝色之前完成。在标准流程中，片段的结果被存放到了merger stage中。ROVs(rasterizer order views)光栅化顺序视图 在DX11,3中被引入来确保执行的顺序。和UAV类似，他们可以以同样的方式被任何着色器读写。关键性的不同是在ROV中，它保证了数据以正确的顺序被访问。这大大增加了这些着色器可访问缓冲区的实用性。例如，Rov使像素着色器可以编写自己的混合方法，因为它可以直接访问和写入Rov中的任何位置，因此不需要合并阶段。但是这样做的代价是，如果如果检测到无序访问，像素着色器调用可能会暂停，直到它前面绘制的三角形被处理完成

### 3.9合并阶段

和在2.5.2中讨论的一样，混合阶段是熟读和独立的片段的颜色（在像素着色器中生成的）和帧缓存结合的地方。DX将这个地方称作是output merger，opgl称它为逐样本操作（per sample operation）。 在传统的流水线示意图中，（包括我们自己），这个阶段是模板缓冲和z-缓存发生的地方。如果片段式可见的，另外一个会执行的操作就是颜色混合（color blending）,对于不透明的表面，并没有真正意义上的混合，因为只是简单的使用片段的颜色取代了以前存储的颜色。实际上，混合片段和存储的颜色通常是用于透明读和融合操作

想想一下，一个被光栅化生成的片段通过了像素着色器，然后在应用z-buffer时被一些先前呈现的片段所隐藏。因此所有在片段着色器中运行的操作是没有必要的。为了避免这个浪费，一些GPU会在像素着色器之前执行一些合并测试（megering test）。片段的的z-值（任何其他正在使用的，如模板缓冲或剪切）被用来做测试是否可见。被隐藏的片段将会被剔除。这个功能被称为early-z。像素着色器有能力改变片段的的z值或者是丢弃整个片段。如果在一个像素着色程序中发现上述任何一种类型的操作，那么early-z通常不能使用并会被关闭，通常这样会让整个流水线效率下降。DX11和OPGL4.2允许像素着色器通过一些限制强制early-z 是开启状态。有效的使用early-z能够对性能有非常大的影响

合并阶段占据了固定功能阶段(如三角形设置)和完全可编程的着色阶段之间的中间地带。 尽管它是不能够编程的，这个操作是高度可配置的。特别是颜色混合可以设置来执行大量不同的操作 。最常见的是涉及颜色和alpha值的乘法、加法和减法的组合，但也可以进行其他操作，如最小值和最大值，以及按位逻辑操作。DX10 增加了从像素着色器和帧缓冲颜色混合两种颜色的能力。 这种能力被称为双源-颜色混合，不能与多个渲染目标一起使用。而DX10,1引入了在不同的buffer中进行不同的混合操作的能力

就像上一节中结尾提到的那样，DX11.3提供了一个在ROV中让混合操作可编程化的方法，尽管这会带来一定的消耗。ROV 和合并阶段都保证了绘制顺序，又称为输出不变性。 不管像素着色器结果是按什么顺序生成的，api都要求将结果按输入、一个对象一个对象和一个三角形一个三角形的顺序排序并发送到合并阶段

### 3.10 ComputeShader(计算着色器)

GPU不仅可以用于实现传统的图形流水线，还可以用于计算股票期权的估值和训练神经网络进行深度学习等多种领域的非图形化应用。这种方式使用硬件被称为GPU 计算。类似于CUDA和OPCL这样的平台用Gpu来做高并发的计算平台。没有任何需要用到图形计算的地方。这些框架经常使用带插件的C++或C语言和以及为gpu制作的库开发。

由DX11引入，compute shader(计算着色器)也是一种GPU计算，它是一个没有被锁定在图形管道中的某个位置的着色器。它与渲染过程密切相关，因为它是由图形API调用的.它与顶点、像素和其他着色器一起使用。它利用了与流水线中使用的相同的统一着色处理器池,。它是一个和其他着色器一样的着色器，因为它有一些输入数据集，并且可以访问输入和输出的缓冲(例如纹理)。 扭曲和线程在计算着色器中更明显。 还有一个线程组的概念，它由1到1024个线程组成。 这些线程组是由x、y和z坐标指定的，主要是为了在着色器代码中使用简单。 每个线程组都有一小部分在线程组之间共享的内存。在DX11中，它的数量是32kb。计算着色器是通过线程组执行的，以便确保组中的所有线程都可以并发运行 。

一个计算着色器的优点是他们能够访问GPU生成的数据。在CPU和GPU之间传输数据会导致延时，所以如果处理过程和结果能够在GPU上能够提高性能。后处理，即以某种方式修改渲染图像，是计算着色器的常用用法。共享的内存意味着采样图像像素的中间结果可以与相邻线程共享。举个例子，使用计算着色器来确定图像的分布或平均亮度，它的运行速度是在像素着色器上执行此操作的两倍

计算着色器在其他方面也是很有用的，例如说粒子系统，网格处理例如面部动画，裁剪，图像过滤，提高深度精度，阴影，景深，以及任何其他一组GPU处理器可以承担的任务。Wihlidal讨论了如何让计算着色器可以镶嵌阶段的hull着色器更有效率。

![fig316](.\fig316.png)

这结束了我们对gpu实现渲染管道的回顾。 有很多方法可以使用和组合gpu函数来执行各种与渲染相关的过程。 为利用这些功能而调整的相关理论和算法是本书的中心主题。 我们现在的重点是转换和阴影

#### 更多的阅读资源

~看原文

## 第四章 变换（transforms）

变换是一个将顶点，向量，甚至是颜色按照一定的方式变换的一个操作。熟悉变换是非常重要的。它们可以确定位置，变形，还可以让对象，光照，摄像机动起来。而且也能够保证所有的计算的结果都是在同一个坐标系空间下的，并以不同的方式将物体投射到平面上。这些只是转换可以执行的少数操作，但是它们足以证明转换在实时图形中，或者就此而言，在任何计算机图形中所扮演的角色的重要性 。

线性变换(liner transform)是一种保持向量加法和标量乘法的变换

  ![linertransform](D:\t\learning\linertransform.png)

举一个例子，f(x) = 5x 是让一个向量的所有值都乘以五的变换，为了证明它是线性的，两个条件都必须被满足。第一个条件是成立的，因为任意两个向量乘以5和相加等于两个向量相加再相乘。第二个条件标量乘法的条件显然满足  。这个函数被称为缩放函数，它会修改一个对象的缩放（大小）。旋转变换是另外一种线性变换，它会基于原点？旋转一个向量。缩放和旋转变换，事实上所有对3个元素的向量的线性变换，都可以被一个3x3矩阵所表示

但是这种大小的矩阵通常来说是不够大的。一个给三元向量做变换的函数，例如f(x) = x+(7,3,2)是非线性的，在两个单独的向量上执行此函数将从结果中将(7,3,2)的每个值相加两次。对一个向量增加一个固定的向量值是执行一个平移，它会将所有位置都移动一个固定的值。这是一种非常有用的变换，我们比较喜欢将多种变换进行组合。比如说，在计算机图形学中，我们时常想要把各种变换结合起来，如先把一个物体缩小一半，再绕某个轴旋转90度，再平移到某个位置。但这种结合无法只用一个简单的3D矩阵实现。

为了结合线性变换和平移变换可以使用**仿射变换**(*affine transform*)，通常存储在一个 ![[公式]](https://www.zhihu.com/equation?tex=4%5Ctimes+4) 的矩阵中。仿射变换是一种变换，即先完成线性变换，然后再完成平移变换。为了表示四维向量我们使用[齐次坐标](https://zhuanlan.zhihu.com/p/73123357)，用统一的方式表示点和方向。一个方向向量表示为 ![[公式]](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7BV%7D%3D%28v_x+%5Cquad+v_y+%5Cquad+v_z+%5Cquad+0+%29%5E%5Cboldsymbol%7BT%7D) ，而一个点表示为 ![[公式]](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bv%7D%3D%28v_x+%5Cquad+v_y+%5Cquad+v_z+%5Cquad+1%29%5E%5Cboldsymbol%7BT%7D) 。

所有的平移、旋转、缩放、反射和错切矩阵都是仿射的。仿射变换的主要特征是保持了平行性，即给平行线施加仿射变换后，得到的仍是平行线。但仿射变换不一定保持长度(lengths)和角度(angles)不变。一个仿射变换可能是上面说到的单个仿射变换的连接序列。

本章（机翻）将从最基本的仿射变换开始。 然后描述矩阵，然后四元数，一个强大的转换工具。 然后是顶点混合和变形，它们是两种简单而有效的表达网格动画的方法。 最后,投影。矩阵描述大多数的转换，它们的符号，函数，表4.1总结了正交矩阵的性质

### 4.1基础变换

![4zhangzongjie](D:\t\learning\4zhangzongjie.jpg)

### 4.1.1 平移

一个从一个坐标转移到另外的位置由一个平移矩阵$T$来表示。这个矩阵使用一个向量t=(tx,ty,tz)来进行转换，这个矩阵如下

![translationmatrix](.\translationmatrix.png)

图4.1中有平移矩阵的影响的例子。一个点 $p= (p_x,p_y,p_z)$和$T$的乘积得到一个新的点$p'=（p_x+t_x,p_y+t_y,p_z+t_z）$，这就是一个显而易见的平移。一个方向向量$V=(v_x,v_y,v_z,0)$是不会被平移矩阵影响的，因为方向是不会被平移的。点和向量都受到其余仿射变换的影响。平移矩阵的逆矩阵是$T^{-1}(-t)$，区别就是向量$t$是负数

![nijuzhen](.\nijuzhen.png)

在这一点上，我们应该提到，有时在计算机图形学中看到的另一种有效的表示法是使用底部一行的平移向量的矩阵。注意，此处（前面提到的）的矩阵使用的列优先(*column-major*)形式，在进行平移运算时要这样:$T(t)*p$。也存在另一种形式的平移矩阵，即把平移向量放在矩阵的最后一行，这种被称为行优先形式(*row-major*)，如在DirectX中，平移运算变成这样:$p^T*T(t)$,这里的$p$都是列向量，而$p^T$是它的转置，是行向量。在我们这本书中，我们讨论到的都是列优先形式的。不管哪一种方式被使用，他都是一个符号的区别。当这个矩阵被保存到了内存中，16个值中的最后四个值是三个平移值，后面跟着一个1  

### 4.1.2 旋转

**旋转变换**用一个给定的旋转角度和过原心的旋转轴来旋转一个向量(位置或方向)。和平移矩阵一样，它是一个刚体变换(*rigid-body transform*)，即它保持变换后点之间的距离不变，保持handednes不变(即不会造成左右交换)。这两个矩阵变换对计算位置和定位很有用，方向矩阵（orientation matrix）是一个与摄像机视图或对象相关的旋转矩阵，它定义其在空间中的方向，例如其方向为向上和向前。 

在二维空间中，旋转矩阵是非常好证明的。假设我们有一个向量$v=(v_x,v_y)$,我们可以把它参数化为$v=(v_x,v_y)=(r\cos{\theta},r\sin{\theta})$.而如果我们想要将他（逆时针）旋转$\phi$弧度，那我们会获得 $u=(r\cos(\theta+\phi),r\sin(\theta+\phi))$.这个可以写成

![xuanzhuantuidao](./xuanzhuantuidao.png)

即二维空间中的旋转矩阵为$R(\phi)$.也就是我们用角合关系来展开$\cos(\theta+\phi),r\sin(\theta+\phi)$

在三维空间中常用的旋转矩阵为 $R_x(\phi),R_y(\phi),R_z(\phi)$，它们分别可以把一个向量绕x，y，z轴旋转 $\phi$ 弧度。它们的值为:

![rotationmartix](./rotationmartix.png)

如果在上面的4x4矩阵中删掉右下两行，变成一个3x3的矩阵。对每一个对于每一个绕任意轴旋转$\phi$弧度3x3的旋转矩阵$R$​​（）,它的迹（它是矩阵对角线元素的和 ）是独立于轴的常数，计算为  $tr(R) = 1+2\cos{\phi}$​. 

旋转矩阵的影响在图4.4中可以看到。旋转矩阵$R_i(\phi)$的特征，除了它绕着轴i旋转了$\phi$度，它使所有旋转轴$i$上的点保持不变。这三种轴变换矩阵结合(即矩阵相乘)起来可以表示**任意旋转矩阵**，稍后会说到这一点。

所有旋转矩阵都是正交矩阵并且它们的行列式值都为1。这也适用于任何数量的这些转换的串联。ps:在图形学中常用到正交矩阵，正交矩阵的逆矩阵和转置矩阵相同。旋转矩阵的逆矩阵: $R_i^{-1}(\phi) = R_i(-\phi)$作用是绕同一轴，以相反的方向旋转

例子：绕一个点旋转

![roationpoing](./fig42rotationroundpoing.png)

如图4.2所示，有一个不规则物体，其上有一点 $P$，要绕点 $P$ 旋转物体，则可按如下步骤进行:

1. 对物体施加平移变换 $T(-p)$
2. 对物体施加旋转变换 $R_z(\phi)$这是真正的旋转部分
3. 对物体施加平移变换 $T(p)$

则把这三步的变换矩阵“结合”起来就得到了最终的变换矩阵:$X=T(p)R_z(\phi)T(-p)$

注意这三个矩阵的顺序，要按照从右往左的顺序读，先发生右边的变换(在opgl里面也有提到)。

### 4.1.3缩放

